{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Ab-initio Pipeline Demonstration\n\nThis tutorial demonstrates some key components of an ab-initio\nreconstruction pipeline using synthetic data generated with ASPIRE's\n``Simulation`` class of objects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download a Volume\nWe begin by downloading a high resolution volume map of the 80S\nRibosome, sourced from EMDB: https://www.ebi.ac.uk/emdb/EMD-2660.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nimport os\n\nimport numpy as np\nimport requests\n\n\n# Download volume\ndef download(url, save_path, chunk_size=1024 * 1024):\n    r = requests.get(url, stream=True)\n    with open(save_path, \"wb\") as fd:\n        for chunk in r.iter_content(chunk_size=chunk_size):\n            fd.write(chunk)\n\n\nfile_path = os.path.join(os.getcwd(), \"emd_2660.map\")\nif not os.path.exists(file_path):\n    url = \"https://ftp.ebi.ac.uk/pub/databases/emdb/structures/EMD-2660/map/emd_2660.map.gz\"\n    download(url, file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load a Volume\nWe use ASPIRE's ``Volume`` class to load and downsample the volume.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire.volume import Volume\n\n# Load 80s Ribosome\noriginal_vol = Volume.load(file_path, dtype=np.float32)\n\n# Downsample the volume\nres = 41\nvol = original_vol.downsample(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>A ``Volume`` can be saved using the ``Volume.save()`` method as follows::\n\n        fn = f\"downsampled_80s_ribosome_size{res}.mrc\"\n        vol.save(fn, overwrite=True)</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Simulation Source\nASPIRE's ``Simulation`` class can be used to generate a synthetic\ndataset of projection images.  A ``Simulation`` object produces\nrandom projections of a supplied Volume and applies noise and CTF\nfilters. The resulting stack of 2D images is stored in an ``Image``\nobject.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CTF Filters\nLet's start by creating CTF filters. The ``operators`` package\ncontains a collection of filter classes that can be supplied to a\n``Simulation``.  We use ``RadialCTFFilter`` to generate a set of CTF\nfilters with various defocus values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create CTF filters\nfrom aspire.operators import RadialCTFFilter\n\n# Radial CTF Filter\ndefocus_min = 15000  # unit is angstroms\ndefocus_max = 25000\ndefocus_ct = 7\n\nctf_filters = [\n    RadialCTFFilter(pixel_size=5, defocus=d)\n    for d in np.linspace(defocus_min, defocus_max, defocus_ct)\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize Simulation Object\nWe feed our ``Volume`` and filters into ``Simulation`` to generate\nthe dataset of images.  When controlled white Gaussian noise is\ndesired, ``WhiteNoiseAdder.from_snr()`` can be used to generate a\nsimulation data set around a specific SNR.\n\nAlternatively, users can bring their own images using an\n``ArrayImageSource``, or define their own custom noise functions via\n``Simulation(..., noise_adder=CustomNoiseAdder(...))``.  Examples\ncan be found in ``tutorials/class_averaging.py`` and\n``experiments/simulated_abinitio_pipeline.py``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire.noise import WhiteNoiseAdder\nfrom aspire.source import Simulation\n\n# set parameters\nn_imgs = 2500\n\n# SNR target for white gaussian noise.\nsnr = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Note, the SNR value was chosen based on other parameters for this\n  quick tutorial, and can be changed to adjust the power of the\n  additive noise.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For this ``Simulation`` we set all 2D offset vectors to zero,\n# but by default offset vectors will be randomly distributed.\nsrc = Simulation(\n    n=n_imgs,  # number of projections\n    vols=vol,  # volume source\n    offsets=0,  # Default: images are randomly shifted\n    unique_filters=ctf_filters,\n    noise_adder=WhiteNoiseAdder.from_snr(snr=snr),  # desired SNR\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Several Views of the Projection Images\nWe can access several views of the projection images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# with no corruption applied\nsrc.projections[0:10].show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# with no noise corruption\nsrc.clean_images[0:10].show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# with noise and CTF corruption\nsrc.images[0:10].show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CTF Correction\nWe apply ``phase_flip()`` to correct for CTF effects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "src = src.phase_flip()\nsrc.images[0:10].show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class Averaging\nWe use ``RIRClass2D`` object to classify the images via the\nrotationally invariant representation (RIR) algorithm. Class\nselection is customizable. The classification module also includes a\nset of protocols for selecting a set of images to be used for\nclassification.  Here we're using ``TopClassSelector``, which\nselects the first ``n_classes`` images from the source.  In\npractice, the selection is done by sorting class averages based on\nsome configurable notion of quality.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire.classification import RIRClass2D\n\n# set parameters\nn_classes = 200\nn_nbor = 6\n\n# We will customize our class averaging source. Note that the\n# ``fspca_components`` and ``bispectrum_components`` were selected for\n# this small tutorial.\nrir = RIRClass2D(\n    src,\n    fspca_components=40,\n    bispectrum_components=30,\n    n_nbor=n_nbor,\n)\n\nfrom aspire.denoising import DebugClassAvgSource\n\navgs = DebugClassAvgSource(\n    src=src,\n    classifier=rir,\n)\n\n# We'll continue our pipeline with the first ``n_classes`` from ``avgs``.\navgs = avgs[:n_classes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the Class Averages\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Show class averages\navgs.images[0:10].show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Show original images corresponding to those classes. This 1:1\n# comparison is only expected to work because we used\n# ``TopClassSelector`` to classify our images.\nsrc.images[0:10].show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Orientation Estimation\nWe initialize a ``CLSyncVoting`` class instance for estimating the\norientations of the images.  The estimation employs the common lines\nmethod with synchronization and voting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire.abinitio import CLSyncVoting\n\n# Stash true rotations for later comparison\ntrue_rotations = src.rotations[:n_classes]\n\n# Run orientation estimation on ``avgs``.\norient_est = CLSyncVoting(avgs, n_theta=72)\n\n# Get the estimated rotations\norient_est.estimate_rotations()\nrots_est = orient_est.rotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Squared Error\nASPIRE has some built-in utility functions for globally aligning the\nestimated rotations to the true rotations and computing the mean\nsquared error.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire.utils.coor_trans import (\n    get_aligned_rotations,\n    get_rots_mse,\n    register_rotations,\n)\n\n# Compare with known true rotations\nQ_mat, flag = register_rotations(rots_est, true_rotations)\nregrot = get_aligned_rotations(rots_est, Q_mat, flag)\nmse_reg = get_rots_mse(regrot, true_rotations)\nmse_reg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Volume Reconstruction\nNow that we have our class averages and rotation estimates, we can\nestimate the mean volume by supplying the class averages and basis\nfor back projection.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire.basis import FFBBasis3D\nfrom aspire.reconstruction import MeanEstimator\n\n# Assign the estimated rotations to the class averages\navgs = avgs.update(rotations=rots_est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Outside of internal operations during ``ImageSource``\n    construction, mutating meta data will return a new source\n    object.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a reasonable Basis for the 3d Volume\nbasis = FFBBasis3D(res, dtype=vol.dtype)\n\n# Setup an estimator to perform the back projection.\nestimator = MeanEstimator(avgs, basis)\n\n# Perform the estimation and save the volume.\nestimated_volume = estimator.estimate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison of Estimated Volume with Source Volume\nTo get a visual confirmation that our results are sane, we rotate\nthe estimated volume by the estimated rotations and project along\nthe z-axis.  These estimated projections should align with the\noriginal projection images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from aspire.source import ArrayImageSource\n\n# Get projections from the estimated volume using the estimated\n# orientations.  We instantiate the projections as an\n# ``ArrayImageSource`` to access the ``Image.show()`` method.\nprojections_est = ArrayImageSource(estimated_volume.project(rots_est))\n\n# We view the first 10 projections of the estimated volume.\nprojections_est.images[0:10].show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For comparison, we view the first 10 source projections.\nsrc.projections[0:10].show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}